{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a5e7f3-73ee-451a-b0be-1f0f4cae0e82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To unzip the datasets nii.gz. However, it is not necessory to unzip them because the libriry 'nibabel' below will process zipped data implicitly.\n",
    "# But I did not delete this part, maybe you can learn something in it.\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def decompress_gz_files(folder):\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.gz'):\n",
    "                gz_file_path = os.path.join(root, file)\n",
    "                output_file_path = os.path.splitext(gz_file_path)[0]\n",
    "                # print(f\"Unzipping: {gz_file_path} -> {output_file_path}\")\n",
    "                with gzip.open(gz_file_path, 'rb') as gz_file:\n",
    "                    with open(output_file_path, 'wb') as output_file:\n",
    "                        shutil.copyfileobj(gz_file, output_file)\n",
    "\n",
    "data_dir = r'./brainweb_petmr_v2'\n",
    "decompress_gz_files(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "186b60b5-4099-47c7-9f1d-1af0d8f279d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b''\n",
      "dim_info        : 0\n",
      "dim             : [  3 220 220 184   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 0\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : unknown\n",
      "sform_code      : aligned\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : 1.0\n",
      "qoffset_x       : -0.0\n",
      "qoffset_y       : -0.0\n",
      "qoffset_z       : 0.0\n",
      "srow_x          : [-1. -0. -0. -0.]\n",
      "srow_y          : [-0. -1. -0. -0.]\n",
      "srow_z          : [0. 0. 1. 0.]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n"
     ]
    }
   ],
   "source": [
    "# Output info of dataset\n",
    "import nibabel as nib\n",
    "\n",
    "# load NIfTI files\n",
    "data_dir = r'./brainweb_petmr_v2/subject04/image_0.nii.gz'\n",
    "image = nib.load(data_dir)\n",
    "\n",
    "# get file data\n",
    "image_data = image.get_fdata()\n",
    "\n",
    "# check header info\n",
    "header = image.header\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a8fd31-983d-491a-9364-eb9857afab11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029beacaa5c74bf3bb5d5b543e39c7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=92, description='slice_num', max=183), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_nii_slice(slice_num)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "# load NIfTI files\n",
    "data_dir = r'./brainweb_petmr_v2/subject04/image_1.nii.gz'\n",
    "# data_dir = r'./brainweb_petmr_v2/subject04/image_0.nii.gz'\n",
    "image = nib.load(data_dir)\n",
    "image_data = image.get_fdata()  # Extract data as NumPy array\n",
    "\n",
    "# ensure image is 3D\n",
    "# assert image_data.ndim == 3, \"error!\"\n",
    "\n",
    "num_slices = image_data.shape[2]  # assume z-axis as slice direction\n",
    "\n",
    "def show_nii_slice(slice_num):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image_data[:, :, slice_num], cmap='gray')\n",
    "    plt.title(f'NIfTI Slice {slice_num + 1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "interact(show_nii_slice, slice_num=IntSlider(min=0, max=num_slices - 1, step=1, value=num_slices // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de16bd9e-44ba-4156-a079-e7a93fd40899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e886af42d8d49d192a213cdef89c553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=92, description='slice_num', max=183), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_noisy_nii_slice(slice_num)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "# load NIfTI files\n",
    "data_dir = r'./brainweb_petmr_v2/subject04/image_1.nii.gz'\n",
    "# data_dir = r'./brainweb_petmr_v2/subject04/image_0.nii.gz'\n",
    "image = nib.load(data_dir)\n",
    "image_data = image.get_fdata()  # Extract data as NumPy array\n",
    "\n",
    "# ensure image is 3D\n",
    "# assert image_data.ndim == 3, \"error!\"\n",
    "\n",
    "# add poisson noise\n",
    "noisy_image_data = np.random.poisson(image_data)\n",
    "\n",
    "num_slices = noisy_image_data.shape[2]\n",
    "\n",
    "def show_noisy_nii_slice(slice_num):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(noisy_image_data[:, :, slice_num], cmap='gray')\n",
    "    plt.title(f'Noisy NIfTI Slice {slice_num + 1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "interact(show_noisy_nii_slice, slice_num=IntSlider(min=0, max=num_slices - 1, step=1, value=num_slices // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4d692ce-e399-44e2-bf18-7e59233e4b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset shape: (1160, 1, 220, 220)\n",
      "Data has been successfully saved as 'training_sinograms_noisefree.npy'.\n"
     ]
    }
   ],
   "source": [
    "# create training dataset\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Set the data directory\n",
    "data_dir = './brainweb_petmr_v2'\n",
    "\n",
    "# Initialize an empty list to store slice data\n",
    "all_slices = []\n",
    "\n",
    "# Iterate over each subject folder (assuming each folder starts with \"subject\")\n",
    "for subject_folder in os.listdir(data_dir):\n",
    "    subject_path = os.path.join(data_dir, subject_folder)\n",
    "    if os.path.isdir(subject_path) and subject_folder.startswith('subject'):\n",
    "        # For each subject, load image_0 and image_1\n",
    "        for image_file in ['image_0.nii.gz', 'image_1.nii.gz']:\n",
    "            image_path = os.path.join(subject_path, image_file)\n",
    "            if os.path.exists(image_path):\n",
    "                # Load the image file\n",
    "                image = nib.load(image_path)\n",
    "                image_data = image.get_fdata()  # Extract as a NumPy array\n",
    "                \n",
    "                # Get the center slice index\n",
    "                center_slice = image_data.shape[2] // 2\n",
    "                \n",
    "                # Determine the range of slices (center ± 14 slices, total 35 slices)\n",
    "                start_slice = max(0, center_slice - 14)\n",
    "                end_slice = min(image_data.shape[2], center_slice + 15)  # Exclusive\n",
    "                \n",
    "                # Extract the slices and add them to all_slices\n",
    "                slices = image_data[:, :, start_slice:end_slice]\n",
    "                all_slices.extend([slices[:, :, i] for i in range(slices.shape[2])])\n",
    "\n",
    "# Combine all slices into a single NumPy array\n",
    "all_slices_array = np.array(all_slices)\n",
    "\n",
    "# Add a new dimension to the data\n",
    "all_slices_array = np.expand_dims(all_slices_array, axis=1)  # Shape: (N, 1, 220, 220)\n",
    "\n",
    "# Ensure the data is correct\n",
    "print(f\"Total dataset shape: {all_slices_array.shape}\")\n",
    "\n",
    "# Save as a .npy file\n",
    "os.makedirs('./PET_data/Train_npy', exist_ok=True)\n",
    "np.save('./PET_data/Train_npy/training_sinograms_noisefree.npy', all_slices_array)\n",
    "\n",
    "print(\"Data has been successfully saved as 'training_sinograms_noisefree.npy'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ab388ea-aeaf-47d7-9e61-fb28cec2b352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset after adding noise: (1160, 1, 220, 220)\n",
      "Noise has been successfully added and saved as 'training_sinograms_noisy.npy'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the original noise-free dataset\n",
    "noisefree_data = np.load('./PET_data/Train_npy/training_sinograms_noisefree.npy')\n",
    "\n",
    "# Initialize an empty list to store noisy slices\n",
    "noisy_slices = []\n",
    "\n",
    "# Iterate over each slice, adding Poisson noise to each 2D image in the slice\n",
    "for slice in noisefree_data:\n",
    "    # slice has shape (1, 220, 220), so we extract the 2D image using slice[0]\n",
    "    noisy_image = np.random.poisson(slice[0])  # Add Poisson noise\n",
    "    noisy_slices.append(noisy_image[np.newaxis, :, :])  # Add back the channel dimension\n",
    "\n",
    "# Convert the list of noisy slices to a NumPy array\n",
    "noisy_slices_array = np.array(noisy_slices)\n",
    "\n",
    "# Ensure the data is correct\n",
    "print(f\"Shape of the dataset after adding noise: {noisy_slices_array.shape}\")\n",
    "\n",
    "# Save the new dataset with added noise\n",
    "np.save('./PET_data/Train_npy/training_sinograms_noisy.npy', noisy_slices_array)\n",
    "\n",
    "print(\"Noise has been successfully added and saved as 'training_sinograms_noisy.npy'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca962b0-b7f7-4971-bf92-e545d4901ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset shape: (580, 1, 220, 220)\n",
      "Data has been successfully saved as 'test_sinograms_noisefree.npy'.\n"
     ]
    }
   ],
   "source": [
    "# create test dataset\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Set the data directory\n",
    "data_dir = './brainweb_petmr_v2'\n",
    "\n",
    "# Initialize an empty list to store slice data\n",
    "all_slices = []\n",
    "\n",
    "# Iterate over each subject folder (assuming each folder starts with \"subject\")\n",
    "for subject_folder in os.listdir(data_dir):\n",
    "    subject_path = os.path.join(data_dir, subject_folder)\n",
    "    if os.path.isdir(subject_path) and subject_folder.startswith('subject'):\n",
    "        # For each subject, load image_0 and image_1\n",
    "        for image_file in ['image_2.nii.gz']:\n",
    "            image_path = os.path.join(subject_path, image_file)\n",
    "            if os.path.exists(image_path):\n",
    "                # Load the image file\n",
    "                image = nib.load(image_path)\n",
    "                image_data = image.get_fdata()  # Extract as a NumPy array\n",
    "                \n",
    "                # Get the center slice index\n",
    "                center_slice = image_data.shape[2] // 2\n",
    "                \n",
    "                # Determine the range of slices (center ± 14 slices, total 35 slices)\n",
    "                start_slice = max(0, center_slice - 14)\n",
    "                end_slice = min(image_data.shape[2], center_slice + 15)  # Exclusive\n",
    "                \n",
    "                # Extract the slices and add them to all_slices\n",
    "                slices = image_data[:, :, start_slice:end_slice]\n",
    "                all_slices.extend([slices[:, :, i] for i in range(slices.shape[2])])\n",
    "\n",
    "# Combine all slices into a single NumPy array\n",
    "all_slices_array = np.array(all_slices)\n",
    "\n",
    "# Add a new dimension to the data\n",
    "all_slices_array = np.expand_dims(all_slices_array, axis=1)  # Shape: (N, 1, 220, 220)\n",
    "\n",
    "# Ensure the data is correct\n",
    "print(f\"Total dataset shape: {all_slices_array.shape}\")\n",
    "\n",
    "# Save as a .npy file\n",
    "os.makedirs('./PET_data/Test_npy', exist_ok=True)\n",
    "np.save('./PET_data/Train_npy/test_sinograms_noisefree.npy', all_slices_array)\n",
    "\n",
    "print(\"Data has been successfully saved as 'test_sinograms_noisefree.npy'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f665ca6-727a-4a35-a5fe-642472e10991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset after adding noise: (580, 1, 220, 220)\n",
      "Noise has been successfully added and saved as 'test_sinograms_noisy.npy'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the original noise-free dataset\n",
    "noisefree_data = np.load('./PET_data/Train_npy/test_sinograms_noisefree.npy')\n",
    "\n",
    "# Initialize an empty list to store noisy slices\n",
    "noisy_slices = []\n",
    "\n",
    "# Iterate over each slice, adding Poisson noise to each 2D image in the slice\n",
    "for slice in noisefree_data:\n",
    "    # slice has shape (1, 220, 220), so we extract the 2D image using slice[0]\n",
    "    noisy_image = np.random.poisson(slice[0])  # Add Poisson noise\n",
    "    noisy_slices.append(noisy_image[np.newaxis, :, :])  # Add back the channel dimension\n",
    "\n",
    "# Convert the list of noisy slices to a NumPy array\n",
    "noisy_slices_array = np.array(noisy_slices)\n",
    "\n",
    "# Ensure the data is correct\n",
    "print(f\"Shape of the dataset after adding noise: {noisy_slices_array.shape}\")\n",
    "\n",
    "# Save the new dataset with added noise\n",
    "np.save('./PET_data/Test_npy/test_sinograms_noisy.npy', noisy_slices_array)\n",
    "\n",
    "print(\"Noise has been successfully added and saved as 'test_sinograms_noisy.npy'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reconstruction)",
   "language": "python",
   "name": "reconstruction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
