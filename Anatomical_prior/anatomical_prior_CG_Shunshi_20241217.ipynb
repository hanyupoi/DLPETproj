{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca1410e-a7a7-486c-bc29-e54f6b154f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import odl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.data import shepp_logan_phantom\n",
    "from skimage.transform import resize,radon,iradon\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from skimage.transform import radon, iradon\n",
    "from scipy.optimize import approx_fprime\n",
    "from scipy.sparse.linalg import eigsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8fffcf8-b023-455a-8046-2ecdd15fb7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Get objective function\n",
    "global reco_space, angle_partition, detector_partition, geometry, ray_trafo,ray_trafo_adjoint,fbp\n",
    "reco_space = odl.uniform_discr(min_pt=[-20, -20], max_pt=[20, 20], shape=[300, 300], dtype='float32')\n",
    "angle_partition = odl.uniform_partition(0, np.pi, 1800)\n",
    "detector_partition = odl.uniform_partition(-30, 30, 500)\n",
    "geometry = odl.tomo.Parallel2dGeometry(angle_partition, detector_partition)\n",
    "# Create the foward operator \n",
    "ray_trafo = odl.tomo.RayTransform(reco_space,geometry)\n",
    "ray_trafo_adjoint=ray_trafo.adjoint\n",
    "fbp = odl.tomo.fbp_op(ray_trafo, filter_type='Hann', frequency_scaling=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3269edb4-6f50-4b37-9945-9ec057bd523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_outside_circle(img):\n",
    "    n = img.shape[0]\n",
    "    y, x = np.ogrid[:n, :n]\n",
    "    center = (n - 1) / 2.0\n",
    "    mask = (x - center)**2 + (y - center)**2 <= center**2\n",
    "    img[~mask] = 0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07daa5cd-09ea-44a6-bd9a-6154ca51fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shepp_logan_data(shape=(300,300)):\n",
    "    #Create phantom\n",
    "    anat_phantom = odl.phantom.shepp_logan(reco_space, modified=True)\n",
    "    # max_val = np.max(anat_phantom)\n",
    "    # scale_factor = 100.0 / max_val\n",
    "    # emission_phantom = anat_phantom * scale_factor #Rescale\n",
    "    shepp_logan = odl.phantom.shepp_logan(reco_space,modified = True)\n",
    "    phantom_array = shepp_logan.asarray().copy()\n",
    "    x, y = np.meshgrid(np.linspace(-20, 20, 300), np.linspace(-20, 20, 300))\n",
    "    hot_spot = ((x - 5)**2 + (y - 5)**2) < 2**2\n",
    "    phantom_array[hot_spot] = phantom_array.max() * 0.8\n",
    "    phantom_array *= 0.7\n",
    "    modified_phantom = reco_space.element(phantom_array)\n",
    "    pet_data = ray_trafo(modified_phantom)\n",
    "    pet_data = odl.phantom.poisson_noise(pet_data)* 1.0 #add noise\n",
    "    # pet_data /= np.max(pet_data)\n",
    "    return anat_phantom, modified_phantom, pet_data\n",
    "# # visualization\n",
    "# fig, axes = plt.subplots(1, 3)\n",
    "# axes[0].imshow(anat_phantom, cmap='gray')\n",
    "# axes[0].set_title(\"Generated CT Image\")\n",
    "# axes[1].imshow(emission_phantom, cmap='hot')\n",
    "# axes[1].set_title(\"Generated PET Image\")\n",
    "# axes[2].imshow(pet_data, cmap='gray')\n",
    "# axes[2].set_title(\"Generated PET data\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456fba79-d939-49ec-a9ed-5d1a594c9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bowsher weighted function\n",
    "def psi(u, zeta=0.5, rho=0.01):\n",
    "    return (np.arctan((zeta - u) / rho) / np.pi) + 0.5\n",
    "    \n",
    "def bowsher_weights(anat_phantom, voxel, neighbors,zeta=0.5, rho=0.01,epsilon=1e-6):\n",
    "    central_value = anat_phantom[voxel]\n",
    "    neighbor_values = np.array([anat_phantom[n] for n in neighbors])\n",
    "    \n",
    "    Mj = np.max(np.abs(central_value - neighbor_values))\n",
    "    Mk_values = [np.max(np.abs(anat_phantom[n] - neighbor_values)) for n in neighbors]\n",
    "    \n",
    "    denominator = (Mj + np.array(Mk_values)) / 2\n",
    "    denominator = np.maximum(denominator, epsilon)\n",
    "    \n",
    "    weights = psi(np.abs(central_value - neighbor_values) / denominator, zeta, rho)\n",
    "    return weights / np.sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "323045b5-ac2a-43c3-bae7-a3982bfa1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP objective function\n",
    "def map_objective(recon_image, pet_data, regularization):\n",
    "    recon_image = recon_image.reshape(shape)\n",
    "    recon_projected = ray_trafo(recon_image)\n",
    "    likelihood = odl.solvers.iterative.statistical.poisson_log_likelihood(recon_projected,pet_data)\n",
    "    prior = regularization\n",
    "    gradient = compute_map_gradient(recon_image, pet_data, anat_phantom, shape)\n",
    "    return -likelihood + prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b4abd59-52f7-4f5e-b5ed-d321a737729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_map_gradient(recon_image, pet_data, anat_phantom, shape, alpha=0.01, beta=1.0):\n",
    "    # Reshape reconstruction image\n",
    "    recon_image = recon_image.reshape(shape)\n",
    "    \n",
    "    # Compute gradient of likelihood term\n",
    "    recon_projected = ray_trafo(recon_image)\n",
    "    likelihood_grad = ray_trafo_adjoint(1 - pet_data / (recon_projected + 1e-6))\n",
    "    \n",
    "    # Compute gradient of regularization term\n",
    "    reg_grad = np.zeros_like(recon_image)\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            voxel = (i, j)\n",
    "            neighbors = get_neighbors(voxel, shape)\n",
    "            weights = bowsher_weights(anat_phantom, voxel, neighbors, beta)\n",
    "            voxel_value = recon_image[voxel]\n",
    "            for k, neighbor in enumerate(neighbors):\n",
    "                neighbor_value = recon_image[neighbor]\n",
    "                reg_grad[voxel] += 2 * alpha * weights[k] * (voxel_value - neighbor_value)\n",
    "    \n",
    "    # Combine gradients\n",
    "    map_gradient = likelihood_grad + reg_grad\n",
    "    return map_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f64a4e-2ead-469e-a2bf-25af32228a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anatomical information regularization term\n",
    "def anatomical_regularization(parameters, anat_phantom, shape, alpha=0.1, beta=1.0):\n",
    "    penalty = 0\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            voxel = (i, j)\n",
    "            neighbors = get_neighbors(voxel, shape)\n",
    "            weights = bowsher_weights(anat_phantom, voxel, neighbors, beta)\n",
    "            voxel_value = parameters[voxel]\n",
    "            neighbor_values = np.array([parameters[neighbor] for neighbor in neighbors])\n",
    "            penalty += alpha * np.sum(weights * (voxel_value - neighbor_values) ** 2)\n",
    "    return penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca32d83-a16e-41d0-9881-acf857f3ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 8 neighbor voxels  \n",
    "def get_neighbors(voxel, shape):\n",
    "    x, y = voxel\n",
    "    neighbors = []\n",
    "    for dx in [-1, 0, 1]:\n",
    "        for dy in [-1, 0, 1]:\n",
    "            if dx == 0 and dy == 0:\n",
    "                continue\n",
    "            nx, ny = x + dx, y + dy\n",
    "            if 0 <= nx < shape[0] and 0 <= ny < shape[1]:\n",
    "                neighbors.append((nx, ny))\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e419a06-912c-4466-8a0c-8b35c120b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAPObjective(odl.solvers.Functional):\n",
    "    def __init__(self, space, pet_data, anat_phantom, shape, regularization_func, ray_trafo, alpha=0.01, beta=1.0):\n",
    "        super().__init__(space)\n",
    "        self.pet_data = pet_data\n",
    "        self.anat_phantom = anat_phantom\n",
    "        self.shape = shape\n",
    "        self.regularization_func = regularization_func\n",
    "        self.ray_trafo = ray_trafo\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def __call__(self, x):\n",
    "        recon_image = x.asarray().reshape(self.shape)\n",
    "        recon_projected = self.ray_trafo(recon_image)\n",
    "        likelihood = odl.solvers.iterative.statistical.poisson_log_likelihood(\n",
    "            recon_projected, self.pet_data\n",
    "        )\n",
    "        prior = self.regularization_func(recon_image, self.anat_phantom, self.shape, self.alpha, self.beta)\n",
    "        return -likelihood + prior\n",
    "\n",
    "    @property\n",
    "    def gradient(self):\n",
    "        class GradientOperator(odl.Operator):\n",
    "            def __init__(self, space, objective):\n",
    "                super().__init__(space, space)\n",
    "                self.objective = objective\n",
    "\n",
    "            def _call(self, x, out):\n",
    "                recon_image = x.asarray().reshape(self.objective.shape)\n",
    "            \n",
    "                grad = compute_map_gradient(\n",
    "                    recon_image,\n",
    "                    self.objective.pet_data,\n",
    "                    self.objective.anat_phantom,\n",
    "                    self.objective.shape,\n",
    "                    self.objective.alpha,\n",
    "                    self.objective.beta\n",
    "                )\n",
    "            \n",
    "                out_arr = out.asarray()\n",
    "                np.copyto(out_arr, grad)  \n",
    "\n",
    "        return GradientOperator(self.domain, self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad1f354-301b-4ace-9013-95149a5e5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization\n",
    "def optimize_parameters(pet_data, anat_phantom, shape, alpha=0.01, beta=1.0):\n",
    "    # Using fbp result as initial\n",
    "    # initial_params=fbp(pet_data)\n",
    "    # initial_params = np.maximum(initial_params, 0)\n",
    "    # initial_params = np.asarray(initial_params).flatten()\n",
    "    \n",
    "    # Using one matrix as initial\n",
    "    # initial_params = np.ones(shape).flatten()\n",
    "\n",
    "    # Using MlEM result as initial\n",
    "    initial_params= ray_trafo.domain.one()\n",
    "    odl.solvers.iterative.statistical.mlem(ray_trafo, initial_params, pet_data, 1)\n",
    "    #Optimization\n",
    "    space = odl.uniform_discr(min_pt=[-20, -20], max_pt=[20, 20], shape=shape)\n",
    "    # Objective function\n",
    "    objective = MAPObjective(space, pet_data, anat_phantom, shape, alpha, beta)\n",
    "    initial_params = space.element(initial_params)\n",
    "    odl.solvers.smooth.nonlinear_cg.conjugate_gradient_nonlinear(objective, initial_params, maxiter=15)\n",
    "    return initial_params\n",
    "    return initial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1926b1a4-d433-4ed8-83d2-e305488f5982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the image's quality\n",
    "def evaluate_quality(reference, reconstructed):\n",
    "    data_range = reference.max() - reference.min()\n",
    "    psnr = peak_signal_noise_ratio(reference, reconstructed,data_range=1.0)\n",
    "    ssim = structural_similarity(reference, reconstructed,data_range=1.0)\n",
    "    return psnr, ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383235e4-9325-4e5f-a0d3-2dd0e2b02a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    anat_phantom, emission_phantom,pet_data = generate_shepp_logan_data()\n",
    "    shape = emission_phantom.shape\n",
    "    estimated_params = optimize_parameters(pet_data, anat_phantom, shape)\n",
    "    \n",
    "    # visualization\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"PET Image (Shepp-Logan Phantom)\")\n",
    "plt.imshow(emission_phantom, cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"PET Data\")\n",
    "plt.imshow(pet_data, cmap='gray', aspect='auto')  # 调整 aspect 使其更自然\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Reconstructed Image\")\n",
    "plt.imshow(estimated_params, cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout(w_pad=3.0, h_pad=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15f9eb-bc50-487f-b145-95679e3abb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Determine whether the function is non-convex\n",
    "# def hessian(func, x, epsilon=1e-5):\n",
    "#     \"\"\"\n",
    "#      Hessian matrix\n",
    "#     \"\"\"\n",
    "#     x = np.asarray(x)\n",
    "#     n = x.shape[0]\n",
    "#     hess = np.zeros((n, n))\n",
    "#     for i in range(n):\n",
    "#         for j in range(n):\n",
    "#             x_ij1 = x.copy()\n",
    "#             x_ij2 = x.copy()\n",
    "#             x_ij3 = x.copy()\n",
    "#             x_ij4 = x.copy()\n",
    "#             x_ij1[i] += epsilon\n",
    "#             x_ij1[j] += epsilon\n",
    "#             x_ij2[i] += epsilon\n",
    "#             x_ij2[j] -= epsilon\n",
    "#             x_ij3[i] -= epsilon\n",
    "#             x_ij3[j] += epsilon\n",
    "#             x_ij4[i] -= epsilon\n",
    "#             x_ij4[j] -= epsilon\n",
    "#             hess[i, j] = (func(x_ij1) - func(x_ij2) - func(x_ij3) + func(x_ij4)) / (4 * epsilon ** 2)\n",
    "#     return hess\n",
    "\n",
    "# # Check if Hessian is positive definite\n",
    "# def is_hessian_positive_semidefinite(hessian_matrix):\n",
    "#     # characteristic value\n",
    "#     min_eigenvalue = np.min(np.linalg.eigvalsh(hessian_matrix))\n",
    "#     return min_eigenvalue >= 0\n",
    "# def wrapped_map_objective(parameters):\n",
    "#     emission_phantom = parameters.reshape(shape)\n",
    "#     regularization = anatomical_regularization(parameters, anat_phantom, shape)\n",
    "#     return map_objective(emission_phantom, pet_data, regularization)\n",
    "\n",
    "# shape = emission_phantom.shape\n",
    "# parameters=emission_phantom\n",
    "# regularization = anatomical_regularization(parameters, anat_phantom, shape)\n",
    "# objecticve_function=map_objective(emission_phantom, pet_data, regularization)\n",
    "\n",
    "# # Hessian matrix\n",
    "# hess = hessian(wrapped_map_objective, parameters)\n",
    "\n",
    "# is_convex = is_hessian_positive_semidefinite(hess)\n",
    "# if is_convex:\n",
    "#     print(\"objective function is convex（Hessian matrix is positive definite）。\")\n",
    "# else:\n",
    "#     print(\"objective function is not convex（Hessian matrix has minus characteristic value）。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd13549c-4136-4654-bf16-55f28c86f258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (recon_odl)",
   "language": "python",
   "name": "recon_odl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
