{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libaries\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "from skimage.transform import radon, iradon\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from perlin_noise import PerlinNoise\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from scipy.ndimage import rotate\n",
    "import cv2\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Import the DIP repository, make sure to clone https://github.com/DmitryUlyanov/deep-image-prior\n",
    "import sys\n",
    "sys.path.append('C:/Users/Administrator/deep-image-prior')\n",
    "from models import skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sinogram_2d(image_2d, angles):\n",
    "    # Get image dimensions\n",
    "    rows, cols = image_2d.shape\n",
    "    # Calculate the radius of the circle\n",
    "    radius = min(rows, cols) // 2\n",
    "    # Create a mask to zero out areas outside the circle\n",
    "    Y, X = np.ogrid[:rows, :cols]\n",
    "    center_y, center_x = rows / 2, cols / 2\n",
    "    mask = (X - center_x)**2 + (Y - center_y)**2 <= radius**2\n",
    "    image_masked = image_2d * mask\n",
    "    # Generate sinogram\n",
    "    sinogram = radon(image_masked, theta=angles, circle=True)\n",
    "    return sinogram\n",
    "\n",
    "\n",
    "def add_poisson_noise(sinogram, scale=1e4):\n",
    "    # Ensure there are no negative values (Poisson noise requires non-negative input)\n",
    "    sinogram_clipped = np.clip(sinogram, 0, None)\n",
    "    \n",
    "    # Scale up the intensity values to approximate \"photon counts\"\n",
    "    sinogram_scaled = sinogram_clipped * scale\n",
    "    \n",
    "    # Generate Poisson noise (random photon counts)\n",
    "    sinogram_noisy_scaled = np.random.poisson(sinogram_scaled).astype(np.float32)\n",
    "    \n",
    "    # Scale back down to the original magnitude\n",
    "    sinogram_noisy = sinogram_noisy_scaled / scale\n",
    "    return sinogram_noisy\n",
    "\n",
    "\n",
    "def backproject(sinogram, angles):\n",
    "    reconstructed = np.zeros((sinogram.shape[1], sinogram.shape[1]))\n",
    "    for i, angle in enumerate(angles):\n",
    "        rotated_projection = rotate(np.tile(sinogram[i], (sinogram.shape[1], 1)).T, -angle, reshape=False)\n",
    "        reconstructed += rotated_projection\n",
    "    return reconstructed / len(angles)\n",
    "\n",
    "\n",
    "def generate_sinogram(image, num_angles=180):\n",
    "    angles = np.linspace(0, 180, num_angles, endpoint=False)\n",
    "    sinogram = np.array([np.sum(rotate(image, angle, reshape=False), axis=0) for angle in angles])\n",
    "    return sinogram, angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLEM_reconstruction(sinogram, angles, reference_image, num_iterations=50):\n",
    "    # Initialize the image with ones\n",
    "    image_shape = (sinogram.shape[1], sinogram.shape[1])\n",
    "    reconstructed = np.ones(image_shape, dtype=np.float32)\n",
    "    psnr_values = []\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        # E-Step: Forward projection\n",
    "        forward_projection = radon(reconstructed, theta=angles, circle=True)\n",
    "        \n",
    "        # Ensure matching shapes for division\n",
    "        if forward_projection.shape != sinogram.shape:\n",
    "            forward_projection = forward_projection[: sinogram.shape[0], :]\n",
    "        \n",
    "        # Compute the ratio\n",
    "        ratio = sinogram / (forward_projection + epsilon)\n",
    "        \n",
    "        # M-Step: Backprojection of the ratio\n",
    "        back_projection = iradon(ratio, theta=angles, filter_name=None, circle=True)\n",
    "        \n",
    "        # Update the reconstructed image\n",
    "        reconstructed *= back_projection\n",
    "        \n",
    "        # Regularization to ensure non-negative image\n",
    "        reconstructed = np.maximum(reconstructed, 0)\n",
    "        \n",
    "        # Compute PSNR\n",
    "        psnr_value = cv2.PSNR(reference_image.astype(np.float32), reconstructed.astype(np.float32))\n",
    "        psnr_values.append(psnr_value)\n",
    "    \n",
    "    return reconstructed, psnr_values\n",
    "\n",
    "def plot_psnr(psnr_values):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(range(1, len(psnr_values) + 1), psnr_values,  linestyle='-')\n",
    "    plt.xlabel(\"Number of Iterations\")\n",
    "    plt.ylabel(\"PSNR (dB)\")\n",
    "    plt.title(\"PSNR vs. Number of Iterations for MLEM Reconstruction\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dicom reader\n",
    "def load_dicom_series(folder_path):\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dicom_names = reader.GetGDCMSeriesFileNames(folder_path)\n",
    "    if not dicom_names:\n",
    "        raise ValueError(f\"No DICOM files found in {folder_path}\")\n",
    "    reader.SetFileNames(dicom_names)\n",
    "    image = reader.Execute()\n",
    "    return image\n",
    "\n",
    "def normalize_image(image):\n",
    "    img_array = sitk.GetArrayFromImage(image).astype(np.float32)\n",
    "    img_min = np.min(img_array)\n",
    "    img_max = np.max(img_array)\n",
    "    if img_max - img_min < 1e-5:\n",
    "        return np.zeros_like(img_array)\n",
    "    else:\n",
    "        return (img_array - img_min) / (img_max - img_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image registration\n",
    "def register_pet_ct(ct_image, pet_image, mode=\"upsample_PET\"):\n",
    "    # Initialize the registration method\n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "\n",
    "    # Set multi-resolution pyramid strategy\n",
    "    registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[4, 2, 1])\n",
    "    registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[2, 1, 0])\n",
    "    registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "    # Set registration metric\n",
    "    registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "    registration_method.SetMetricSamplingPercentage(0.01)\n",
    "\n",
    "    # Set transformation type (rigid transformation)\n",
    "    initial_transform = sitk.CenteredTransformInitializer(\n",
    "        ct_image,\n",
    "        pet_image,\n",
    "        sitk.Euler3DTransform(),\n",
    "        sitk.CenteredTransformInitializerFilter.GEOMETRY\n",
    "    )\n",
    "\n",
    "    registration_method.SetInitialTransform(initial_transform, inPlace=False)\n",
    "\n",
    "    # Set optimizer\n",
    "    registration_method.SetOptimizerAsGradientDescent(learningRate=1.0,\n",
    "                                                      numberOfIterations=100,\n",
    "                                                      convergenceMinimumValue=1e-6,\n",
    "                                                      convergenceWindowSize=10)\n",
    "    registration_method.SetOptimizerScalesFromPhysicalShift()\n",
    "\n",
    "    # Set interpolation method\n",
    "    registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "\n",
    "    try:\n",
    "        final_transform = registration_method.Execute(sitk.Cast(ct_image, sitk.sitkFloat32),\n",
    "                                                      sitk.Cast(pet_image, sitk.sitkFloat32))\n",
    "        print(\"Optimizer Converged:\", registration_method.GetOptimizerStopConditionDescription())\n",
    "        print(\"Final Metric Value:\", registration_method.GetMetricValue())\n",
    "    except Exception as e:\n",
    "        print(f\"\\nRegistration failed: {e}\")\n",
    "        raise e\n",
    "\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetInterpolator(sitk.sitkLinear)\n",
    "    resampler.SetDefaultPixelValue(0)\n",
    "    resampler.SetTransform(final_transform)\n",
    "\n",
    "    if mode == \"upsample_PET\":\n",
    "        resampler.SetReferenceImage(ct_image)\n",
    "        pet_resampled = resampler.Execute(pet_image)\n",
    "        print(\"Resampling completed.\")\n",
    "        return ct_image, pet_resampled\n",
    "\n",
    "    elif mode == \"downsample_CT\":\n",
    "        resampler.SetReferenceImage(pet_image)\n",
    "        ct_resampled = resampler.Execute(ct_image)\n",
    "        print(\"Resampling completed.\")\n",
    "        return ct_resampled, pet_image\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode selection, mode should be 'upsample_PET' or 'downsample_CT'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design for Bowsher prior Filter \n",
    "def apply_bayesian_filter(image_2d, sigma=1.0, zeta=0.5, rho=0.01, alpha=0.001):\n",
    "    # Compute the Bayesian kernel (Bowsher-like prior)\n",
    "    kernel = compute_bowsher_kernel_2d(image_2d, zeta=zeta, rho=rho, alpha=alpha)\n",
    "    filtered_image = image_2d * kernel\n",
    "    return filtered_image\n",
    "\n",
    "def compute_kernel_2d(ct_2d, sigma=1.0):\n",
    "    # Compute the gradient of the CT image\n",
    "    gradient_x = gaussian_filter(ct_2d, sigma=sigma, order=1, mode='nearest')\n",
    "    gradient_y = gaussian_filter(ct_2d, sigma=sigma, order=1, mode='nearest')\n",
    "    gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "\n",
    "    # Design a bilateral kernel, assigning lower weights to edges\n",
    "    kernel = np.exp(- (gradient_magnitude ** 2))\n",
    "    return kernel\n",
    "\n",
    "def psi(u, zeta=0.5, rho=0.01):\n",
    "    return (np.arctan((zeta - u) / rho) / np.pi) + 0.5\n",
    "\n",
    "def Tq_linear(value):\n",
    "    return value\n",
    "\n",
    "def compute_bowsher_kernel_2d(\n",
    "    ct_image_2d, \n",
    "    zeta=0.5, \n",
    "    rho=0.01, \n",
    "    Tq_func=Tq_linear, \n",
    "    epsilon=1e-6,\n",
    "    alpha = 0.001\n",
    "):\n",
    "    # Offsets for the 8 neighbors in (dy, dx)\n",
    "    neighbor_offsets = [\n",
    "        (-1, -1), (-1, 0), (-1, 1),\n",
    "        ( 0, -1),          ( 0, 1),\n",
    "        ( 1, -1), ( 1, 0), ( 1, 1)\n",
    "    ]\n",
    "    \n",
    "    H, W = ct_image_2d.shape\n",
    "    weights_2d = np.zeros((H, W, len(neighbor_offsets)), dtype=np.float32)\n",
    "\n",
    "    # Pre-compute Tq for the entire image to avoid repeated calls\n",
    "    transformed_ct = Tq_func(ct_image_2d)\n",
    "\n",
    "    # For each pixel, we need M_j = max|Tq(mu_j) - Tq(mu_k)| over neighbors\n",
    "    M_array = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "    for y in range(H):\n",
    "        for x in range(W):\n",
    "            central_val = transformed_ct[y, x]\n",
    "            diffs = []\n",
    "            for dy, dx in neighbor_offsets:\n",
    "                ny, nx = y + dy, x + dx\n",
    "                if 0 <= ny < H and 0 <= nx < W:\n",
    "                    neighbor_val = transformed_ct[ny, nx]\n",
    "                    diffs.append(abs(central_val - neighbor_val))\n",
    "            if len(diffs) > 0:\n",
    "                M_array[y, x] = max(diffs)\n",
    "            else:\n",
    "                M_array[y, x] = 0.0\n",
    "\n",
    "    # Compute the actual weights for each neighbor\n",
    "    for y in range(H):\n",
    "        for x in range(W):\n",
    "            central_val = transformed_ct[y, x]\n",
    "            Mj = M_array[y, x]\n",
    "            \n",
    "            for n_idx, (dy, dx) in enumerate(neighbor_offsets):\n",
    "                ny, nx = y + dy, x + dx\n",
    "                if not (0 <= ny < H and 0 <= nx < W):\n",
    "                    # Out of bounds, weight = 0\n",
    "                    weights_2d[y, x, n_idx] = 0.0\n",
    "                    continue\n",
    "                \n",
    "                neighbor_val = transformed_ct[ny, nx]\n",
    "                Mk = M_array[ny, nx]\n",
    "                \n",
    "                denom = (Mj + Mk) / 2.0\n",
    "                denom = denom if denom > epsilon else epsilon\n",
    "                \n",
    "                diff = abs(central_val - neighbor_val)\n",
    "                u_jk = diff / denom\n",
    "                \n",
    "                w_jk = psi(u_jk, zeta=zeta, rho=rho)\n",
    "                weights_2d[y, x, n_idx] = w_jk\n",
    "\n",
    "    kernel = np.sum(weights_2d, axis=-1)\n",
    "    kernel = np.exp(alpha * kernel) \n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(image, angles):\n",
    "    return radon(image, theta=angles, circle=True)\n",
    "\n",
    "def backproject(sinogram, angles):\n",
    "    if isinstance(sinogram, torch.Tensor):\n",
    "        sinogram = sinogram.cpu().numpy()\n",
    "    return iradon(sinogram, theta=angles, circle=True)\n",
    "\n",
    "\n",
    "def apply_filter(image, method=\"bilateral\", sigma=1.0, zeta=0.5, rho=0.01, alpha=0.001, ct_prior=None):\n",
    "\n",
    "    image_np = image.detach().cpu().numpy() \n",
    "\n",
    "    if method == \"bilateral\":\n",
    "        filtered_image = cv2.bilateralFilter(image_np.astype(np.float32), d=9, sigmaColor=sigma*50, sigmaSpace=sigma*50)\n",
    "    \n",
    "    elif method == \"anisotropic\":\n",
    "        filtered_image = denoise_tv_chambolle(image_np, weight=sigma)\n",
    "    \n",
    "    elif method == \"gaussian\":\n",
    "        filtered_image = gaussian_filter(image_np, sigma=sigma)\n",
    "    \n",
    "    elif method == \"bayesian\":\n",
    "        filtered_image = apply_bayesian_filter(image_np, sigma=sigma, zeta=zeta, rho=rho, alpha=alpha)\n",
    "    \n",
    "    elif method == \"gradient\":\n",
    "        if ct_prior is None:\n",
    "            raise ValueError(\"CT prior required for gradient-based kernel filtering.\")\n",
    "\n",
    "        # Precompute the anatomical kernel\n",
    "        if ct_prior is not None:\n",
    "            ct_prior_np = ct_prior.squeeze().detach().cpu().numpy()\n",
    "            kernel = compute_kernel_2d(ct_prior_np, sigma=sigma)\n",
    "\n",
    "\n",
    "        #ct_prior_np = ct_prior.squeeze().detach().cpu().numpy()\n",
    "        #kernel = compute_kernel_2d(ct_prior_np, sigma=sigma)  # Compute anatomical gradient kernel\n",
    "        filtered_image = image_np * kernel  # Weight input image by anatomical kernel\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose 'bilateral', 'anisotropic', 'gaussian', 'bayesian', or 'gradient'.\")\n",
    "\n",
    "    return torch.tensor(filtered_image, dtype=torch.float32).to(image.device)\n",
    "\n",
    "\n",
    "def KEM_step(image, sinogram, angles, kernel_size, sigma=1.0, filter_method=\"bilateral\", ct_prior=None, num_em_iterations=5):\n",
    "    device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "    updated_image = image.clone()  # Ensure iterate on a copy\n",
    "\n",
    "    for _ in range(num_em_iterations):  # Iterate multiple EM steps\n",
    "        # Step 1: Forward project\n",
    "        forward_projection = project(updated_image.squeeze().detach().cpu().numpy(), angles) # radon transformation\n",
    "        forward_projection = torch.tensor(forward_projection, dtype=torch.float32).to(device)\n",
    "\n",
    "        # Step 2: Compute ratio\n",
    "        ratio = sinogram / (forward_projection + 1e-8)\n",
    "        ratio = ratio.clamp(min=0, max=10)  # Prevent extreme values\n",
    "\n",
    "        # Step 3: Backproject ratio update\n",
    "        back_projection = backproject(ratio.cpu().numpy(), angles)\n",
    "        back_projection = torch.tensor(back_projection, dtype=torch.float32).to(device)\n",
    "\n",
    "        # Step 4: Apply filtering\n",
    "        smoothed_image = apply_filter(updated_image.squeeze(), method=filter_method, sigma=sigma, ct_prior=ct_prior)\n",
    "\n",
    "        # Step 5: Update estimate\n",
    "        updated_image.mul_(smoothed_image) # same as updated_image = smoothed_image * back_projection but this is better for memory allocation\n",
    "        #updated_image = updated_image / updated_image.max()  # Normalize\n",
    "\n",
    "    return updated_image.unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_KEM_reconstruction(sinogram, angles, filter_method=\"bayesian\", num_iterations=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    image_shape = (sinogram.shape[1], sinogram.shape[1]) \n",
    "    print(\"Sinogram shape:\", sinogram.shape)\n",
    "    print(\"Reconstructed image shape:\", image_shape)\n",
    "    reconstructed = torch.ones(image_shape, dtype=torch.float32, device=device)\n",
    "\n",
    "    # Convert sinogram to torch tensor\n",
    "    sinogram_torch = torch.tensor(sinogram, dtype=torch.float32, device=device)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        forward_projection = torch.tensor(radon(reconstructed, theta=angles, circle=True), dtype=torch.float32, device=device)\n",
    "\n",
    "        ratio = sinogram_torch / (forward_projection + 1e-6)\n",
    "        \n",
    "        back_projection_np = iradon(ratio.cpu().numpy(), theta=angles, filter_name=None, circle=True)\n",
    "\n",
    "        back_projection = torch.tensor(back_projection_np, dtype=torch.float32, device=device)\n",
    "\n",
    "        if filter_method is not None:\n",
    "            filtered_image = apply_filter(reconstructed, method=filter_method, sigma=sigma, ct_prior=ct_prior)\n",
    "        else:\n",
    "            filtered_image = back_projection  # No filtering\n",
    "\n",
    "        reconstructed = back_projection * filtered_image\n",
    "        reconstructed = torch.clamp(reconstructed, min=0)  # Ensure non-negative values\n",
    "\n",
    "    return reconstructed.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_DIP_reconstruction(sinogram, angles, ct_prior, num_epochs=1000):\n",
    "    device = torch.device(\"cpu\")  # Use CPU for computation\n",
    "\n",
    "    # Initialize image with FBP reconstruction\n",
    "    #initial_image = backproject(sinogram, angles)\n",
    "    initial_image = run_KEM_reconstruction(sinogram, angles, filter_method=\"bayesian\", num_iterations=5)\n",
    "    current_image = torch.tensor(initial_image, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    # Normalize and resize CT prior\n",
    "    ct_prior = torch.tensor(ct_prior, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    #ct_prior = (ct_prior - ct_prior.min()) / (ct_prior.max() - ct_prior.min())  # Normalize to [0,1]\n",
    "\n",
    "    if ct_prior.shape != current_image.shape:\n",
    "        ct_prior = torch.nn.functional.interpolate(ct_prior, size=current_image.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    # current_image and ct_prior should have 2 channels\n",
    "    # Concatenate along the channel dimension (dim=1)\n",
    "    multi_channel_input = torch.cat((current_image, ct_prior), dim=1)\n",
    "\n",
    "    input_depth = 2\n",
    "    net = skip(\n",
    "        input_depth, 1,  # Single-channel grayscale output\n",
    "        num_channels_down=[16, 32, 64, 128, 128],  # Downsampling layers\n",
    "        num_channels_up=[16, 32, 64, 128, 128],  # Upsampling layers\n",
    "        num_channels_skip=[4, 4, 4, 4, 4],  # Skip connections to maintain spatial info\n",
    "        upsample_mode='bilinear',  # Interpolation mode for upsampling\n",
    "        need_sigmoid=True,  # Sigmoid activation for output (keeps values in [0,1])\n",
    "        need_bias=True,  # Adds bias terms\n",
    "        pad='reflection',  # Padding type (reflection padding helps prevent artifacts)\n",
    "        act_fun='LeakyReLU'  # Activation function in convolution layers\n",
    "    ).to(device)\n",
    "    net = net.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Define optimizer for DIP\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.008)\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(multi_channel_input)  # The input should now have 2 channels\n",
    "        \n",
    "        # Now both output and multi_channel_input should have the same size\n",
    "        loss = mse_loss(output, multi_channel_input)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return output.detach().cpu().numpy().squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used right now\n",
    "\n",
    "def DIP_to_KEM(sinogram, angles, ct_prior, kernel_size, num_iterations=10, dip_iterations=100, sigma=1.0, filter_method=\"bilateral\", alpha=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Step 1: Initial Reconstruction using KEM\n",
    "    initial_kem = run_KEM_reconstruction(sinogram, angles, filter_method=filter_method, num_iterations=num_iterations)\n",
    "    plt.imshow(initial_kem, cmap='gray')\n",
    "    plt.title(\"Initial KEM as INPUT\")\n",
    "    plt.show\n",
    "    current_image = torch.tensor(initial_kem, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    # Normalize and resize CT prior\n",
    "    ct_prior = ct_prior.clone().detach().float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "    ct_prior = (ct_prior - ct_prior.min()) / (ct_prior.max() - ct_prior.min())  # Normalize CT prior\n",
    "    if ct_prior.shape[2:] != current_image.shape[2:]:\n",
    "        ct_prior = F.interpolate(ct_prior, size=current_image.shape[2:], mode=\"bilinear\", align_corners=False)  # Resize CT prior\n",
    "\n",
    "    # Define DIP Network\n",
    "    input_depth = 2\n",
    "    net = skip(\n",
    "        input_depth, 1,\n",
    "        num_channels_down=[16, 32, 64, 128, 128],\n",
    "        num_channels_up=[16, 32, 64, 128, 128],\n",
    "        num_channels_skip=[4, 4, 4, 4, 4],\n",
    "        upsample_mode='bilinear',\n",
    "        need_sigmoid=True,\n",
    "        need_bias=True,\n",
    "        pad='reflection',\n",
    "        act_fun='LeakyReLU'\n",
    "    ).to(device)\n",
    "\n",
    "    # Define optimizer for DIP\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.008)\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "    # DIP input (multi-channel: noise + CT), FBP + CT is best\n",
    "    multi_channel_input = torch.cat((current_image, ct_prior), dim=1)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Perform DIP first (in image-space regularization)\n",
    "        for _ in range(dip_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            dip_output = net(multi_channel_input)\n",
    "            \n",
    "            # Use KEM to enforce fidelity (data space to image space)\n",
    "            kem_output = KEM_step(dip_output, sinogram, angles, kernel_size, sigma, filter_method=\"bayesian\", ct_prior=ct_prior)\n",
    "\n",
    "            # Combine DIP and KEM outputs\n",
    "            fidelity_loss = mse_loss(dip_output, kem_output)\n",
    "\n",
    "            # Convert tensors to NumPy for SSIM calculation\n",
    "            dip_np = dip_output.squeeze().detach().cpu().numpy()\n",
    "            ct_np = ct_prior.squeeze().detach().cpu().numpy()\n",
    "\n",
    "            # Structural similarity loss (align with CT)\n",
    "            ssim_loss = 1 - ssim(dip_np, ct_np, data_range=1.0)\n",
    "            total_loss = fidelity_loss + 0.1 * ssim_loss  # Weighted loss function\n",
    "            total_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        # Update current_image with the DIP output and apply KEM next\n",
    "        current_image = dip_output.detach()\n",
    "\n",
    "        # Perform KEM (data-space regularization)\n",
    "        kem_output = KEM_step(current_image, sinogram, angles, kernel_size, sigma, filter_method=\"bayesian\", ct_prior=ct_prior)\n",
    "        current_image = kem_output.clone()  # Update current image with KEM result\n",
    "\n",
    "    # Convert final image to NumPy array for visualization\n",
    "    final_image = current_image.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    return final_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation to evaluate with PSNR, MSE and SSIM value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluate_reconstruction(ground_truth, reconstructed):\n",
    "    mse_val = mse(ground_truth, reconstructed)\n",
    "    rmse_val = np.sqrt(mse_val)\n",
    "    psnr_val = cv2.PSNR(ground_truth.astype(np.float32), reconstructed.astype(np.float32))\n",
    "    ssim_val = ssim(ground_truth, reconstructed, data_range=ground_truth.max() - ground_truth.min())\n",
    "\n",
    "    return mse_val, psnr_val, ssim_val, rmse_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load functions if DICOM data is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(ct_folder_path, pet_folder_path):\n",
    "    # Load images\n",
    "    print(\"Loading CT image...\")\n",
    "    ct_image = load_dicom_series(ct_folder_path)\n",
    "    print(\"Loading PET image...\")\n",
    "    pet_image = load_dicom_series(pet_folder_path)\n",
    "\n",
    "    # Print image information\n",
    "    def print_image_info(name, image):\n",
    "     print(f\"\\n{name} Image Information:\")\n",
    "     print(f\"  Size: {image.GetSize()}\")\n",
    "     print(f\"  Spacing: {image.GetSpacing()}\")\n",
    "     print(f\"  Origin: {image.GetOrigin()}\")\n",
    "     print(f\"  Direction: {image.GetDirection()}\")\n",
    "     print(f\"  Dimension: {image.GetDimension()}\")\n",
    "\n",
    "    print_image_info(\"CT\", ct_image)\n",
    "    print_image_info(\"PET\", pet_image)\n",
    "\n",
    "    # Ensure both are 3D images\n",
    "    if ct_image.GetDimension() != 3 or pet_image.GetDimension() != 3:\n",
    "        raise ValueError(\"Both CT and PET images must be 3D.\")\n",
    "\n",
    "    # Ensure both are float32\n",
    "    ct_image = sitk.Cast(ct_image, sitk.sitkFloat32)\n",
    "    pet_image = sitk.Cast(pet_image, sitk.sitkFloat32)\n",
    "\n",
    "    #mode = \"upsample_PET\"\n",
    "    mode = \"downsample_CT\"\n",
    "    ct_image_resampled, pet_image_resampled = register_pet_ct(ct_image, pet_image, mode=mode)\n",
    "\n",
    "    # ================== 3) Select Middle Slice and Generate Sinogram ==================\n",
    "\n",
    "    # Select middle slice\n",
    "    ct_array = sitk.GetArrayFromImage(ct_image_resampled)  # shape: [slices, height, width]\n",
    "    pet_array = sitk.GetArrayFromImage(pet_image_resampled)  # shape: [slices, height, width]\n",
    "\n",
    "    middle_slice_idx = ct_array.shape[0] // 2\n",
    "    ct_slice = ct_array[middle_slice_idx, :, :]\n",
    "    pet_slice = pet_array[middle_slice_idx, :, :]\n",
    "\n",
    "    # Normalize\n",
    "    ct_norm = normalize_image(ct_image_resampled)\n",
    "    pet_norm = normalize_image(pet_image_resampled)\n",
    "    ct_slice_norm = ct_norm[middle_slice_idx, :, :]\n",
    "    pet_slice_norm = pet_norm[middle_slice_idx, :, :]\n",
    "    initial_kernel_size = ct_slice_norm\n",
    "\n",
    "    # Generate sinogram\n",
    "    angles = np.linspace(0., 180., max(ct_slice.shape), endpoint=False)\n",
    "    pet_sinogram = generate_sinogram_2d(pet_slice_norm, angles)\n",
    "    pet_sinogram = add_poisson_noise(pet_sinogram, scale=1) # decrease the number to increase the noise, 0.1 was extremly noisy \n",
    "\n",
    "    return pet_sinogram, ct_slice, ct_slice_norm, initial_kernel_size, pet_slice, pet_slice_norm, angles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here starts main: Load CT Image, PET Image and create noisy PET Sinogram -----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example image DICOM\n",
    "#ct_folder_path = r\"C:\\Users\\Administrator\\OneDrive - stud.hs-mannheim.de\\Dokumente\\PCC3\\NIH\\PET\\CT_1.3.6.1.4.1.14519.5.2.1.7009.2403.798861112144623421423086363370\"\n",
    "#pet_folder_path = r\"C:\\Users\\Administrator\\OneDrive - stud.hs-mannheim.de\\Dokumente\\PCC3\\NIH\\PET\\PT_1.3.6.1.4.1.14519.5.2.1.7009.2403.291916523874874486349020167447\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pet_sinogram, ct_slice, ct_slice_norm, initial_kernel_size, pet_slice, pet_slice_norm, angles = load_images(ct_folder_path, pet_folder_path)\n",
    "\n",
    "#ct_prior_norm = ct_slice_norm\n",
    "#ct_prior = ct_slice\n",
    "\n",
    "#Normalize PET slice to [0,1]\n",
    "#pet_slice_norm = (pet_slice - np.min(pet_slice)) / (np.max(pet_slice) - np.min(pet_slice))\n",
    "#ground_truth = pet_slice_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_prior = cv2.imread(\"ct_image.png\", cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "ground_truth = cv2.imread(\"ground_truth.png\", cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "\n",
    "print(\"CT Prior Shape:\", ct_prior.shape)\n",
    "print(\"Ground Truth Shape:\", ground_truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values for reconstruction\n",
    "kernel_size = 5  # Example kernel size for KEM\n",
    "num_iterations = 10  # Total iterations for the KEM + DIP process\n",
    "dip_iterations = 100  # Number of iterations for DIP\n",
    "sigma = 1.0  # Standard deviation for filtering\n",
    "angles = np.linspace(0., 180., max(ct_prior.shape), endpoint=False)\n",
    "\n",
    "pet_sinogram = generate_sinogram_2d(ground_truth, angles)\n",
    "pet_sinogram = add_poisson_noise(pet_sinogram, scale=0.1) # decrease the number to increase the noise, 0.1 was extremly noisy \n",
    "\n",
    "\n",
    "# Plot CT image, PET Image and both sinograms\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "im1 = axes[0].imshow(ct_prior, cmap='gray')\n",
    "axes[0].set_title(\"CT Prior\")\n",
    "axes[0].axis(\"off\")\n",
    "fig.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "im2 = axes[1].imshow(pet_sinogram, cmap='gray', aspect='auto')\n",
    "axes[1].set_title(\"PET Sinogram\")\n",
    "axes[1].axis(\"off\")\n",
    "fig.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "im3 = axes[2].imshow(ground_truth, cmap='gray')\n",
    "axes[2].set_title(\"Ground Truth\")\n",
    "axes[2].axis(\"off\")\n",
    "fig.colorbar(im3, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function as standalone for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_kem_result = run_KEM_reconstruction(pet_sinogram, angles, filter_method=\"bayesian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_dip_result = run_DIP_reconstruction(pet_sinogram, angles, ct_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(only_kem_result, cmap='gray')\n",
    "axes[0].set_title('Only KEM Reconstruction')\n",
    "axes[1].imshow(only_dip_result, cmap='gray')\n",
    "axes[1].set_title('Only DIP Reconstruction with CT as Prior')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DIP_to_KEM_new(pet_sinogram, ct_prior, angles, filter_method=\"bayesian\", num_iterations=5, num_epochs=1000):\n",
    "    # Step 1: Initial KEM reconstruction\n",
    "    kem_result = run_KEM_reconstruction(pet_sinogram, angles, filter_method=filter_method, num_iterations=num_iterations)\n",
    "    \n",
    "    # Step 2: Use KEM output as initialization for DIP instead of raw FBP\n",
    "    dip_result = run_DIP_reconstruction(kem_result, angles, ct_prior, num_epochs=num_epochs)\n",
    "\n",
    "    # alpha = 0.7 # More influence from KEM (good for structured details)\n",
    "    # alpha=0.5 # Equal influence\n",
    "    alpha = 0.5\n",
    "    # alpha=0.3 # More influence from DIP (good for noise reduction but may lose detail)\n",
    "\n",
    "    # Step 3: Combine KEM and DIP outputs with a weighted update\n",
    "    combined_result = alpha * kem_result + (1 - alpha) * dip_result\n",
    "\n",
    "    # Step 4: Refine further by passing combined result to KEM again\n",
    "    refined_kem_result = run_KEM_reconstruction(combined_result, angles, filter_method=filter_method, num_iterations=num_iterations)\n",
    "\n",
    "    # Step 5: Use refined KEM output as a prior in another DIP pass\n",
    "    refined_dip_result = run_DIP_reconstruction(refined_kem_result, angles, ct_prior, num_epochs=num_epochs)\n",
    "\n",
    "    # Step 6: Final adaptive combination of KEM and DIP\n",
    "    final_result = alpha* refined_kem_result + (1 - alpha) * refined_dip_result\n",
    "\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_approach = DIP_to_KEM_new(pet_sinogram, ct_prior, angles, filter_method=\"bayesian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlem_reconstructed, psnr_values = MLEM_reconstruction(pet_sinogram, angles, ground_truth, num_iterations=50)\n",
    "plot_psnr(psnr_values)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))  \n",
    "im1 = axes[0].imshow(mlem_reconstructed, cmap='gray')#, clim=[0, 0.07])  \n",
    "axes[0].set_title(\"MLEM Reconstruction\")  \n",
    "axes[0].axis('off')  \n",
    "fig.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04) \n",
    " \n",
    "im2 = axes[1].imshow(ground_truth, cmap='gray')  \n",
    "axes[1].set_title(\"Ground Truth\")  \n",
    "axes[1].axis('off')  \n",
    "fig.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04)  \n",
    "\n",
    "im3 = axes[2].imshow(ground_truth-mlem_reconstructed, cmap='gray')\n",
    "axes[2].set_title(\"Difference (Ground Truth - Reconstruction)\")\n",
    "axes[2].axis('off')\n",
    "fig.colorbar(im3, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results \n",
    "# alpha = 0.5\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
    "img0 = axes[0].imshow(new_approach, cmap='gray')\n",
    "axes[0].set_title('New Combination')\n",
    "axes[0].axis('off')\n",
    "fig.colorbar(img0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "img1= axes[1].imshow(mlem_reconstructed, cmap='gray')\n",
    "axes[1].set_title('MLEM')\n",
    "axes[1].axis('off')\n",
    "fig.colorbar(img1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "\n",
    "def total_variation_loss(image):\n",
    "    \"\"\"TV loss to remove noise while keeping structure.\"\"\"\n",
    "    return torch.mean(torch.abs(image[:, :, :, :-1] - image[:, :, :, 1:])) + \\\n",
    "           torch.mean(torch.abs(image[:, :, :-1, :] - image[:, :, 1:, :]))\n",
    "\n",
    "def gradient_difference_loss(output, ct_prior):\n",
    "    \"\"\"Encourages sharp edges from CT to be preserved.\"\"\"\n",
    "    grad_output_x = output[:, :, :, :-1] - output[:, :, :, 1:]\n",
    "    grad_output_y = output[:, :, :-1, :] - output[:, :, 1:, :]\n",
    "    \n",
    "    grad_ct_x = ct_prior[:, :, :, :-1] - ct_prior[:, :, :, 1:]\n",
    "    grad_ct_y = ct_prior[:, :, :-1, :] - ct_prior[:, :, 1:, :]\n",
    "    \n",
    "    return torch.mean(torch.abs(grad_output_x - grad_ct_x)) + torch.mean(torch.abs(grad_output_y - grad_ct_y))\n",
    "\n",
    "\n",
    "\n",
    "def run_dip_kem_refinement(kem_image, ct_image, angles, filter_method=\"bayesian\", num_iterations=1000, lr=0.001):\n",
    "    # Ensure device compatibility\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Convert to tensors\n",
    "    kem_recon = torch.tensor(kem_image, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)  # (1,1,H,W)\n",
    "    ct_prior = torch.tensor(ct_image, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)  # (1,1,H,W)\n",
    "\n",
    "    # Normalize images\n",
    "    kem_recon = (kem_recon - kem_recon.min()) / (kem_recon.max() - kem_recon.min())\n",
    "    ct_prior = (ct_prior - ct_prior.min()) / (ct_prior.max() - ct_prior.min())\n",
    "\n",
    "    # Resize CT prior if needed\n",
    "    if ct_prior.shape != kem_recon.shape:\n",
    "        ct_prior = F.interpolate(ct_prior, size=kem_recon.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    # Define DIP Model (Use a skip network like U-Net)\n",
    "    net = skip(2, 1,  # Two channels: KEM + CT Prior\n",
    "        num_channels_down=[16, 32, 64, 128, 128],\n",
    "        num_channels_up=[16, 32, 64, 128, 128],\n",
    "        num_channels_skip=[4, 4, 4, 4, 4],\n",
    "        upsample_mode='bilinear',\n",
    "        need_sigmoid=True, \n",
    "        need_bias=True,\n",
    "        pad='reflection', \n",
    "        act_fun='LeakyReLU').to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    ssim_loss_fn = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "\n",
    "\n",
    "    # DIP Input (Concatenating KEM + CT prior)\n",
    "    dip_input = torch.cat((kem_recon, ct_prior), dim=1)\n",
    "\n",
    "    # Training Loop\n",
    "    for i in range(num_iterations):\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        dip_output = net(dip_input)  # Get refined image\n",
    "    \n",
    "        # Fidelity Loss (KEM)\n",
    "        fidelity_loss = mse_loss(dip_output, kem_recon)\n",
    "\n",
    "        # Structural Similarity Loss (CT Prior)\n",
    "        ssim_loss = 1 - ssim_loss_fn(dip_output, ct_prior)\n",
    "\n",
    "        # Regularization Losses\n",
    "        tv_loss = total_variation_loss(dip_output)\n",
    "        edge_loss = gradient_difference_loss(dip_output, ct_prior)\n",
    "\n",
    "        # Adjust weights (tune these experimentally)\n",
    "        total_loss = fidelity_loss + 0.3 * ssim_loss + 0.05 * tv_loss + 0.5 * edge_loss  \n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Final refined image\n",
    "    final_image = dip_output.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    # Display results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(kem_recon.squeeze().cpu().numpy(), cmap=\"gray\")\n",
    "    plt.title(\"Initial KEM\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(ct_prior.squeeze().cpu().numpy(), cmap=\"gray\")\n",
    "    plt.title(\"CT Prior\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(final_image, cmap=\"gray\")\n",
    "    plt.title(\"Final Refined Image\")\n",
    "    plt.show()\n",
    "\n",
    "    return final_image\n",
    "\n",
    "\n",
    "refined_image = run_dip_kem_refinement(only_kem_result, ct_prior, angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# created a class and put the CT prior deeper in the layers so it's not cutting out the PET information (Tumors) but keep the sharp edges from the CT image\n",
    "class DeepDIP_with_CT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepDIP_with_CT, self).__init__()\n",
    "\n",
    "        # DIP network (KEM as input)\n",
    "        self.net = skip(\n",
    "            1,  # Only KEM as input\n",
    "            1,  # Output single-channel image\n",
    "            num_channels_down=[32, 64, 128, 256, 256],  \n",
    "            num_channels_up=[32, 64, 128, 256, 256],\n",
    "            num_channels_skip=[8, 8, 8, 8, 8],  \n",
    "            upsample_mode='bilinear',\n",
    "            need_sigmoid=True, \n",
    "            need_bias=True,\n",
    "            pad='reflection', \n",
    "            act_fun='LeakyReLU'\n",
    "        )\n",
    "\n",
    "        # Edge extraction for CT prior\n",
    "        self.sobel_x = nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sobel_y = nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=False)\n",
    "        sobel_x_kernel = torch.tensor([[[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]], dtype=torch.float32).unsqueeze(0)\n",
    "        sobel_y_kernel = torch.tensor([[[-1, -2, -1], [0, 0, 0], [1, 2, 1]]], dtype=torch.float32).unsqueeze(0)\n",
    "        self.sobel_x.weight = nn.Parameter(sobel_x_kernel, requires_grad=False)\n",
    "        self.sobel_y.weight = nn.Parameter(sobel_y_kernel, requires_grad=False)\n",
    "\n",
    "    def forward(self, kem, ct_prior):\n",
    "        \"\"\"\n",
    "        Forward pass with adaptive edge control.\n",
    "        \"\"\"\n",
    "        # Extract edges from CT using Sobel filters\n",
    "        ct_edges_x = self.sobel_x(ct_prior)\n",
    "        ct_edges_y = self.sobel_y(ct_prior)\n",
    "        ct_edges = torch.sqrt(ct_edges_x ** 2 + ct_edges_y ** 2)  # Edge magnitude\n",
    "\n",
    "        # **🔹 Apply a threshold to filter weak edges**\n",
    "        edge_threshold = 0.2  # Experiment with this value\n",
    "        ct_edges = torch.where(ct_edges > edge_threshold, ct_edges, torch.tensor(0.0).to(ct_edges.device))\n",
    "\n",
    "        # **🔹 Normalize edges to avoid overly bright areas**\n",
    "        ct_edges = (ct_edges - ct_edges.min()) / (ct_edges.max() - ct_edges.min() + 1e-6)  # Avoid division by zero\n",
    "\n",
    "        # Pass through DIP network\n",
    "        output = self.net(kem)\n",
    "\n",
    "        # **🔹 Learnable Weight Map for CT Edge Contribution**\n",
    "        weight_map = torch.sigmoid(output)  # Generates values between 0 and 1\n",
    "        refined_output = output + weight_map * ct_edges  # Scale CT edges dynamically\n",
    "\n",
    "        return refined_output\n",
    "\n",
    "# -----------------\n",
    "# prevent tumor details from getting blurred\n",
    "def gradient_difference_loss(output, reference):\n",
    "    \"\"\"\n",
    "    Encourages the output to preserve high-frequency details (sharp edges).\n",
    "    \"\"\"\n",
    "    grad_output_x = output[:, :, :-1, :] - output[:, :, 1:, :]\n",
    "    grad_output_y = output[:, :, :, :-1] - output[:, :, :, 1:]\n",
    "\n",
    "    grad_ref_x = reference[:, :, :-1, :] - reference[:, :, 1:, :]\n",
    "    grad_ref_y = reference[:, :, :, :-1] - reference[:, :, :, 1:]\n",
    "\n",
    "    loss_x = F.l1_loss(grad_output_x, grad_ref_x)\n",
    "    loss_y = F.l1_loss(grad_output_y, grad_ref_y)\n",
    "\n",
    "    return loss_x + loss_y\n",
    "\n",
    "\n",
    "# --------------\n",
    "\n",
    "def model2(kem_image, ct_image, angles, filter_method=\"bayesian\"):\n",
    "    # Ensure device compatibility\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    kem_recon = torch.tensor(kem_image, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    ct_prior = torch.tensor(ct_image, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    # Normalize\n",
    "    kem_recon = (kem_recon - kem_recon.min()) / (kem_recon.max() - kem_recon.min())\n",
    "    ct_prior = (ct_prior - ct_prior.min()) / (ct_prior.max() - ct_prior.min())\n",
    "\n",
    "    # Resize CT to match KEM\n",
    "    if ct_prior.shape != kem_recon.shape:\n",
    "        ct_prior = F.interpolate(ct_prior, size=kem_recon.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    # Initialize model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dip_model = DeepDIP_with_CT().to(device)\n",
    "    optimizer = optim.Adam(dip_model.parameters(), lr=0.001)\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    num_iterations = 500\n",
    "    for i in range(num_iterations):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        dip_output = dip_model(kem_recon, ct_prior)\n",
    "\n",
    "        # Compute losses\n",
    "        fidelity_loss = mse_loss(dip_output, kem_recon)  # Keep PET features\n",
    "        ssim_loss = 1 - ssim(dip_output.squeeze().detach().cpu().numpy(), ct_prior.squeeze().detach().cpu().numpy(), data_range=1.0)\n",
    "        edge_loss = gradient_difference_loss(dip_output, ct_prior)  # Edge preservation\n",
    "\n",
    "        # Total loss (adjust weights)\n",
    "        total_loss = fidelity_loss + 0.3 * ssim_loss + 0.5 * edge_loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Iteration {i}/{num_iterations}, Loss: {total_loss.item()}\")\n",
    "\n",
    "    # Get final refined image\n",
    "    final_image = dip_output.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    # Display results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(kem_recon.squeeze().cpu().numpy(), cmap=\"gray\")\n",
    "    plt.title(\"Initial KEM\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(ct_prior.squeeze().cpu().numpy(), cmap=\"gray\")\n",
    "    plt.title(\"CT Prior\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(final_image, cmap=\"gray\")\n",
    "    plt.title(\"Final Refined Image\")\n",
    "    plt.show()\n",
    "\n",
    "    return final_image\n",
    "\n",
    "\n",
    "refined_image = model2(only_kem_result, ct_prior, angles)\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(mlem_reconstructed, cmap='gray')\n",
    "plt.title(\"MLEM\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(ground_truth, cmap='gray')\n",
    "plt.title(\"Ground Truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_image_bayesian = DIP_to_KEM(\n",
    " #   sinogram=torch.tensor(pet_sinogram, dtype=torch.float32),\n",
    "  #  angles=angles,\n",
    "   # ct_prior=torch.tensor(ct_prior, dtype=torch.float32),\n",
    "    #kernel_size=kernel_size,\n",
    "#    num_iterations=num_iterations,\n",
    " #   dip_iterations=dip_iterations,\n",
    "  #  sigma=sigma, \n",
    "   # filter_method=\"bayesian\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "#im1 = axes[0].imshow(final_image_bayesian cmap='gray')\n",
    "#axes[0].set_title(\"Gaussian Kernel\")\n",
    "#axes[0].axis('off')\n",
    "#fig.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04)  \n",
    "\n",
    "#im2 = axes[1].imshow(ground_truth, cmap='gray')\n",
    "#axes[1].set_title(\"Ground Truth\")  \n",
    "#axes[1].axis('off')  \n",
    "#fig.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04)  \n",
    "\n",
    "#im3 = axes[2].imshow(ground_truth-final_image_bayesian, cmap='gray')\n",
    "#axes[2].set_title(\"Difference (Ground Truth - Reconstruction)\")\n",
    "#axes[2].axis('off')\n",
    "#fig.colorbar(im3, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "metrics_mlem = evaluate_reconstruction(ground_truth, mlem_reconstructed)\n",
    "#metrics_model2_reversed_bilateral = evaluate_reconstruction(ground_truth, final_image_bilateral)\n",
    "#metrics_model2_reversed_anisotropic = evaluate_reconstruction(ground_truth, final_image_anisotropic)\n",
    "#metrics_model2_reversed_gaussian = evaluate_reconstruction(ground_truth, final_image_gaussian)\n",
    "metrics_model2_reversed_bayesian = evaluate_reconstruction(ground_truth, refined_image)\n",
    "\n",
    "print(\"MLEM:\")\n",
    "print(f\"MSE: {metrics_mlem[0]:.4f}, PSNR: {metrics_mlem[1]:.2f}, SSIM: {metrics_mlem[2]:.4f}, RMSE: {metrics_mlem[3]:.4f} \\n\")\n",
    "\n",
    "#print(\"Bilateral Kernel:\")\n",
    "#print(f\"MSE: {metrics_model2_reversed_bilateral[0]:.4f}, PSNR: {metrics_model2_reversed_bilateral[1]:.2f}, SSIM: {metrics_model2_reversed_bilateral[2]:.4f}, RMSE: {metrics_model2_reversed_bilateral[3]:.4f} \\n\")\n",
    "\n",
    "#print(\"Anisotropic Kernel:\")\n",
    "#print(f\"MSE: {metrics_model2_reversed_anisotropic[0]:.4f}, PSNR: {metrics_model2_reversed_anisotropic[1]:.4f}, SSIM: {metrics_model2_reversed_anisotropic[2]:.4f}, RMSE: {metrics_model2_reversed_anisotropic[3]:.4f} \\n\")\n",
    "\n",
    "#print(\"Gaussian Kernel:\")\n",
    "#print(f\"MSE: {metrics_model2_reversed_gaussian[0]:.4f}, PSNR: {metrics_model2_reversed_gaussian[1]:.2f}, SSIM: {metrics_model2_reversed_gaussian[2]:.4f}, RMSE: {metrics_model2_reversed_gaussian[3]:.4f} \\n\")\n",
    "\n",
    "print(\"Bayesian Kernel:\")\n",
    "print(f\"MSE: {metrics_model2_reversed_bayesian[0]:.4f}, PSNR: {metrics_model2_reversed_bayesian[1]:.2f}, SSIM: {metrics_model2_reversed_bayesian[2]:.4f}, RMSE: {metrics_model2_reversed_bayesian[3]:.4f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (recon)",
   "language": "python",
   "name": "your_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
